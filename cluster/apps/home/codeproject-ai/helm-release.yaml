---
# yaml-language-server: $schema=https://raw.githubusercontent.com/fluxcd-community/flux2-schemas/main/helmrelease-helm-v2beta1.json
apiVersion: helm.toolkit.fluxcd.io/v2
kind: HelmRelease
metadata:
  name: codeproject-ai
  namespace: home
spec:
  interval: 30m
  chart:
    spec:
      # renovate: registryUrl=https://bjw-s-labs.github.io/helm-charts/
      chart: app-template
      version: 2.6.0
      sourceRef:
        kind: HelmRepository
        name: bjw-s-charts
        namespace: flux-system
  values:

    service:
      main:
        ports:
          http:
            port: 80

    ingress:
      main:
        enabled: true
        annotations:
          # ForwardAuth start
          nginx.ingress.kubernetes.io/auth-method: GET
          nginx.ingress.kubernetes.io/auth-url: |-
            http://authelia.security.svc.cluster.local:8000/api/verify
          nginx.ingress.kubernetes.io/auth-signin: |-
            https://auth.${SECRET_PUBLIC_DOMAIN}?rm=$request_method
          nginx.ingress.kubernetes.io/auth-response-headers: |-
            Remote-User,Remote-Name,Remote-Groups,Remote-Email
          nginx.ingress.kubernetes.io/auth-snippet: |
            proxy_set_header X-Forwarded-Method $request_method;
          # ForwardAuth end
          nginx.ingress.kubernetes.io/whitelist-source-range: ${NGINX_INTERNAL_WHITELIST}
        hosts:
          - host: "cpai.${SECRET_DOMAIN}"
            paths:
              - path: /
                pathType: Prefix
                service:
                  name: main
                  port: http
        className: nginx

    persistence:
      config:
        enabled: true
        type: persistentVolumeClaim
        accessMode: ReadWriteOnce
        size: 100Mi
        storageClass: local-path
        retain: true
        globalMounts:
          - path: /etc/codeproject/ai
      modules:
        enabled: true
        type: persistentVolumeClaim
        accessMode: ReadWriteOnce
        size: 100Mi
        storageClass: local-path
        retain: true
        globalMounts:
          - path: /app/modules

    defaultPodOptions:
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
              - matchExpressions:
                  - key: feature.node.kubernetes.io/custom-nvidia-gpu
                    operator: In
                    values:
                      - "true"
      runtimeClassName: nvidia

    controllers:
      main:
        annotations:
          reloader.stakater.com/auto: "true"
        containers:
          main:
            image:
              repository: codeproject/ai-server
              tag: "cuda12_2-2.5.4"
            env:
              TZ: "${TIMEZONE}"
              CPAI_PORT: 80
            resources:
              requests:
                cpu: 1m
                memory: 100Mi
                nvidia.com/gpu: "1"
              limits:
                cpu: 2000m
                memory: 6000Mi
                nvidia.com/gpu: "1"
